[transmogrifier]
# Each pipeline corresponds to a blueprint section below
pipeline =
 jsonsource
 limitpath
 limittypes
 removeid
 pathfixer
 setlanguage
 constructor
 copyuid
 deserializer
 schemaupdater
 workflowhistory
 datesupdate
 logger

[jsonsource]
# Specify the source folder in the buildout we are importing from
blueprint = collective.jsonmigrator.jsonsource
path = /home/evgtch/eidc-5.1-python2.7/zinstance/src/content-import

[limitpath]
blueprint = collective.transmogrifier.sections.condition
condition = python:str(item['_path']).find('/eidc/administration-folder') == 0

[limittypes]
# Only import News Items, Blog Posts, Images, and Files
# Everything else will be skipped if it doesn't match
blueprint = collective.transmogrifier.sections.condition
condition = python:item['_type'] in ['Document'] 
#, 'File', 'privateFolder', 'Document', 'Link', 'Folder', 'Image', 'documentContainer', 'documentStore']

[removeid]
# The jsonify will have the id we want to use in the `_id` field
# so remove the one from the data we don't want to use
blueprint = collective.transmogrifier.sections.manipulator
delete = id

[pathfixer]
# Remove the old Plone Site ID from the paths so we can import into any new Plone
# site reguardless of its site ID.
blueprint = plone.app.transmogrifier.pathfixer
stripstring = /eidc

[setlanguage]
blueprint = collective.transmogrifier.sections.inserter
key = string:language
value = string:en-gb

[pdb]
blueprint = collective.transmogrifier.sections.breakpoint
condition = python:True

[constructor]
# Here's where the actual magic happens, create the content object in the site
blueprint = collective.transmogrifier.sections.constructor

[copyuid]
# Needed so that the schemaupdater can set the UUID correctly
blueprint = collective.transmogrifier.sections.manipulator
keys = _uid
destination = string:plone.uuid

[deserializer]
# If the data was contained inside of an attached JSON file, stuff that data
# back into the pipline for the next step.
blueprint = transmogrify.dexterity.deserializer

[schemaupdater]
# Now updated the created item from the data in the dictionary that has been
# passed down the pipeline
blueprint = transmogrify.dexterity.schemaupdater

[workflowhistory]
blueprint = collective.jsonmigrator.workflowhistory

[properties]
# Copy each item's zope properties into the the property sheet of the object
blueprint = collective.jsonmigrator.properties

[datesupdate]
# Plone itself includes some nice blueprint sections that are ready to use
# Set creation, modification and effective dates on the object
blueprint = plone.app.transmogrifier.datesupdater

[logger]
# Critical to developing your piplines is the ability to see log output of what has happened
# Use the logger blueprint section to pick and choose what to output into your logs
blueprint = collective.transmogrifier.sections.logger
name = IMPORTER
level = DEBUG
delete =
 text
 _datafield_file
 _datafield_image
